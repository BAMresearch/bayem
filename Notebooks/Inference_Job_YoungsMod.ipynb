{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "import pyro\n",
    "\n",
    "from bayes.parameters import ParameterList\n",
    "from bayes.inference_problem import VariationalBayesProblem, ModelErrorInterface\n",
    "from bayes.Calibration import Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim\n",
    "We have load-displacemnt RAW data as a function of time $t$ for a cylindrical concrete with daimeter $d$.\n",
    "\n",
    "- Here the parameter to inferred (E) is not known beforehand\n",
    "- Known Input : $\\sigma(t)$\n",
    "- Noisy Observed values : $\\epsilon(t)$\n",
    "- To infer : E (Youngs Modulus) and noise (treated as a gaussian and s.d is inferred)\n",
    "    - Gamma Hyperprior for the noise term\n",
    "\n",
    "From the experimental data E in the range ~E10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-2cfaf908e76d>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(path,delimiter=\"\\t\",skiprows=3,skipfooter=125)\n"
     ]
    }
   ],
   "source": [
    "path = 'usecases/youngsModulusConcrete/data/1datengefiltert.txt'\n",
    "data = pd.read_csv(path,delimiter=\"\\t\",skiprows=3,skipfooter=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting , to . so that import the values as float rather than string\n",
    "\n",
    "data['mm.1'] = [x.replace(',', '.') for x in data['mm.1']]\n",
    "\n",
    "data['mm.1'] = data['mm.1'].astype(float)\n",
    "data['mm.2'] = [x.replace(',', '.') for x in data['mm.2']]\n",
    "\n",
    "data['mm.2'] = data['mm.2'].astype(float)\n",
    "data['mm.3'] = [x.replace(',', '.') for x in data['mm.3']]\n",
    "\n",
    "data['mm.3'] = data['mm.3'].astype(float)\n",
    "data['s'] = [x.replace(',', '.') for x in data['s']]\n",
    "\n",
    "data['s'] = data['s'].astype(float)\n",
    "data['kN.1'] = [x.replace(',', '.') for x in data['kN.1']]\n",
    "\n",
    "data['kN.1'] = data['kN.1'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(labels=range(0, 490), axis=0)\n",
    "#data = data.drop(labels=range(600, 667), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100 #As reported by Jorg\n",
    "data['strain'] = ((data['mm.1'] + data['mm.2'] + data['mm.3'])/3)/length\n",
    "\n",
    "dia=0.0985 #As per the .txt file\n",
    "data['stress'] = (data['kN.1']*1000)/(np.pi*(dia/2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.max(data['stress'])-np.min(data['stress']))/(np.max(data['strain']-np.min(data['strain'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['strain'],data['stress'])\n",
    "plt.xlabel('strain')\n",
    "plt.ylabel('stress')\n",
    "plt.title('Experimental Values for last load cycle')\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70-30 training and test split\n",
    "train, test = np.split(data.sample(frac=1, random_state=42), \n",
    "                       [int(.7*len(data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Forward Solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_solve(known_input, latent_para):\n",
    "    assert isinstance(known_input['known_inputs'],np.ndarray)\n",
    "    stress = known_input['known_inputs']\n",
    "    strain = th.tensor(stress)/latent_para\n",
    "    \n",
    "    return strain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference Task\n",
    "- Uniform Prior for the latent variable E\n",
    "- Gamm hyperprior for the noise term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Metadata for Inference problem\n",
    "        \n",
    "prior_hyperparameter = [32E09, 38E09]\n",
    "prior_dist = \"Uniform\"\n",
    "Observed_data = th.tensor(train['strain'].to_numpy())\n",
    "Noise_distribution = \"Normal\"\n",
    "Noise_hyperparameter = None  # TODO: test with correlated noise model\n",
    "HyperPrior_dist = \"Gamma\"\n",
    "Hyperprior_Parameter = [1,1E05]\n",
    "\n",
    " # ---- Metadata for forward solve\n",
    "forward_solve_wrapper = forward_solve\n",
    "forward_solve_known_input = train['stress'].to_numpy()\n",
    "forward_input = {'known_inputs':forward_solve_known_input}\n",
    "\n",
    "# -- Setup the Inference problem\n",
    "infer = Inference(prior_dist, prior_hyperparameter, forward_solve_wrapper, forward_input, Observed_data,\n",
    "                  Noise_distribution, Noise_hyperparameter,HyperPrior_dist,Hyperprior_Parameter)\n",
    "\n",
    "# -- Solve the Inference problem\n",
    "   \n",
    "posterior_para, posterior_noise = infer.run(1000, kernel=\"NUTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The strain values are very small. Need to normalize? What noise hyperprior dist? Their parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Inference Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer.visualize_prior_posterior(posterior_para, posterior_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known input \n",
    "tmp = test['stress'].to_numpy() # AA: Can write a wrapper to read in data if they are in same order (maybe for similar experiment), can also imporrt data from different experiment of the similar specimen\n",
    "new_input_forward = {'known_inputs': tmp}\n",
    "\n",
    "til_X = infer.predict(posterior_para,posterior_noise,new_input_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=np.quantile(til_X,[0.05,0.5,0.95],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(data['s'],pos[1,:])\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(0, 0))\n",
    "#plt.fill_betweenx(test['stress'],pos[0,:],pos[2,:],alpha=0.8, label='Predicted strain')\n",
    "#plt.fill_between(test['stress'],pos[0,:],pos[2,:],alpha=0.8, label='Predicted strain')\n",
    "plt.plot(test['strain'],test['stress'],'g', label='Noisy Experiment')\n",
    "plt.plot(pos[1,:],test['stress'],'b',alpha=0.2)\n",
    "plt.plot(pos[0,:],test['stress'],'b',alpha=0.2,label='Prediction')\n",
    "plt.plot(pos[2,:],test['stress'],'b',alpha=0.2)\n",
    "plt.legend()\n",
    "plt.xlabel('strain')\n",
    "plt.ylabel('stress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(til_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampled_parameters = pyro.sample('test', dist.Normal(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,value in sampled_parameters:\n",
    "    print(name,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_parameters.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
